{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecbc31e8-0d01-479f-aee4-db46303776b8",
   "metadata": {},
   "source": [
    "## Astron Project 1 Group 1 Jacky Peng & Chenyue Pan\n",
    "# Introduction\n",
    "Our Python-based solar eclipse analysis ingests NASA 2001–2025 records, cleans and categorizes events as total, partial, annular, or hybrid, and computes yearly trends and regional patterns. We leverage a custom OpenAI model to generate concise observation tips and cross-cultural interpretations, detect repeating Saros cycles, and match eclipses with historical milestones. Results (Excel tables, PNG charts) are saved under eclipse_analysis_results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a32d61-a797-4a3c-b8b1-6060d18143b0",
   "metadata": {},
   "source": [
    "All the import that used "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1c3496-f866-440b-93ab-549d5957c17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from openai import OpenAI\n",
    "import time\n",
    "import os\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ff4fd9-518d-4f85-af94-5ff0d370b02e",
   "metadata": {},
   "source": [
    "ConfigManager initializes core settings for the eclipse analysis workflow. It specifies the Excel input path and ensures the output directory exists. It retrieves or prompts for an API key, then constructs an OpenAI client for LLM interactions. Business-specific parameters—historical event mappings, eclipse classification rules, color assignments, Saros cycle length, and target regions—are stored as attributes. This centralized configuration object simplifies access to shared global parameters throughout the automated analysis pipeline.  Jacky's Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3682c6e9-2536-46ee-9186-ecfc2dafa366",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigManager:\n",
    "    def __init__(self):\n",
    "        # Basic path configuration\n",
    "        self.excel_path = \"NASA_2001-2025_Solar_Eclipses.xlsx\"\n",
    "        self.output_dir = \"eclipse_analysis_results\"\n",
    "        os.makedirs(self.output_dir, exist_ok=True)\n",
    "        # LLM configuration\n",
    "        self.api_key = os.environ.get(\"DEEPSEEK_API_KEY\") or configparser.ConfigParser().get('API', 'KEY', fallback=None) or input(\"Enter API Key: \")\n",
    "        # Initialize OpenAI client\n",
    "        try:\n",
    "            self.client = OpenAI(api_key=self.api_key, base_url=\"https://babeltower.pro/v1\", timeout=60)\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Failed to initialize OpenAI client: {e}\")\n",
    "        # Validate API key presence\n",
    "        if not self.api_key:\n",
    "            raise ValueError(\"API key is missing or invalid. Please provide a valid DEEPSEEK_API_KEY.\")\n",
    "        self.model_name = \"deepseek-r1\"\n",
    "        # Business configuration\n",
    "        self.historical_events = {\n",
    "            \"2009-07-22\": \"The longest total solar eclipse occurred in China's Yangtze River Basin, observed by over 10 million people.\",\n",
    "            \"2017-08-21\": \"Great American Eclipse: Total eclipse path covered the entire American continent, sparking a nationwide observation craze.\",\n",
    "            \"2020-06-21\": \"Complete annular solar eclipse visible in the Ali Region.\",\n",
    "            \"2023-04-20\": \"Hybrid solar eclipse experienced in Indonesia and Australia; partial eclipse visible in Hainan, China.\"\n",
    "        }\n",
    "        self.classification_dict = {\n",
    "            \"Total Eclipse (Total)\": [\"Total\"],\n",
    "            \"Partial Eclipse (Partial)\": [\"Partial\"],\n",
    "            \"Annular Eclipse (Annular)\": [\"Annular\"],\n",
    "            \"Hybrid Eclipse (Hybrid)\": [\"Hybrid\"]\n",
    "        }\n",
    "        self.color_map = {\n",
    "            \"Total Eclipse (Total)\": \"#FF4444\",\n",
    "            \"Partial Eclipse (Partial)\": \"#FFCC00\",\n",
    "            \"Annular Eclipse (Annular)\": \"#33B5E5\",\n",
    "            \"Hybrid Eclipse (Hybrid)\": \"#99CC00\",\n",
    "            \"Other (Other)\": \"#666666\"\n",
    "        }\n",
    "        self.saros_cycle = 6585\n",
    "        self.target_locations = [\"China\", \"USA\", \"Japan\", \"India\", \"Australia\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9088ce67-094b-492d-80bb-a71dddaa6df9",
   "metadata": {},
   "source": [
    "DataLoader encapsulates logic for loading and preprocessing raw eclipse data. Its constructor accepts a ConfigManager, stores the Excel file path, and initializes DataFrame placeholders. The load_and_preprocess method verifies file existence, reads sheet contents, drops rows with insufficient or mismatched data, converts valid date strings to datetime objects, removes invalid entries, and renames columns for consistency. It prints the count of valid records and returns the cleaned DataFrame ready for further analysis.  Jacky's part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7caeb6-78c2-4e89-88c5-00c306d233be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, config):\n",
    "        self.excel_path = config.excel_path\n",
    "        self.raw_df = None\n",
    "        self.processed_df = None\n",
    "    def load_and_preprocess(self):\n",
    "        \"\"\"Load and preprocess raw data: read Excel, clean, and rename columns.\"\"\"\n",
    "        try:\n",
    "            # Check if Excel file exists\n",
    "            if not os.path.exists(self.excel_path):\n",
    "                raise FileNotFoundError(f\"Excel file not found: {self.excel_path}\")\n",
    "\n",
    "            # Read raw data starting from row 4\n",
    "            self.raw_df = pd.ExcelFile(self.excel_path).parse(header=None)\n",
    "            self.processed_df = self.raw_df.iloc[3:].reset_index(drop=True)\n",
    "\n",
    "            # Assign column names\n",
    "            self.processed_df.columns = [\n",
    "                \"Calendar Date (Link to Global Map)\",\n",
    "                \"TD of Greatest Eclipse\",\n",
    "                \"Eclipse Type (Link to Google Map)\",\n",
    "                \"Saros Series (Link to Saros)\",\n",
    "                \"Eclipse Magnitude\",\n",
    "                \"Central Duration (Link to Path Table)\",\n",
    "                \"Geographic Region of Eclipse Visibility\",\n",
    "                \"Empty Column\"\n",
    "            ]\n",
    "\n",
    "            # Data cleaning\n",
    "            date_col = \"Calendar Date (Link to Global Map)\"\n",
    "            # Keep rows with at least 4 non-null values\n",
    "            self.processed_df = self.processed_df.dropna(thresh=4)\n",
    "            # Filter rows with valid date format (e.g., \"2001 Jun 21\")\n",
    "            self.processed_df = self.processed_df[\n",
    "                self.processed_df[date_col].str.match(r\"\\d{4} [A-Za-z]{3} \\d{1,2}\", na=False)\n",
    "            ]\n",
    "            # Convert date column to datetime type\n",
    "            self.processed_df[date_col] = pd.to_datetime(\n",
    "                self.processed_df[date_col], format=\"%Y %b %d\", errors=\"coerce\"\n",
    "            )\n",
    "            # Remove rows where date conversion failed\n",
    "            self.processed_df = self.processed_df.dropna(subset=[date_col])\n",
    "\n",
    "            # Rename columns for easier subsequent operations\n",
    "            self.processed_df = self.processed_df.rename(columns={\n",
    "                date_col: \"Date\",\n",
    "                \"Eclipse Type (Link to Google Map)\": \"Eclipse_Type\",\n",
    "                \"Geographic Region of Eclipse Visibility\": \"Visible_Region\"\n",
    "            })\n",
    "\n",
    "            print(f\"Data preprocessing completed: Number of valid records = {len(self.processed_df)}\")\n",
    "            return self.processed_df\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"\\nError: {str(e)}\")\n",
    "            print(\"Please check if the file path is correct, or re-download the data from the link below:\")\n",
    "            print(\"NASA Solar Eclipse Data Download Link: https://eclipse.gsfc.nasa.gov/SEdecade/SEdecade2021.html\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"Data processing failed: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e637cb28-b18e-44ae-ae13-8c100d5b697c",
   "metadata": {},
   "source": [
    "EclipseClassifier takes a preprocessed DataFrame and a mapping of raw eclipse types to human-readable categories. Its constructor stores the DataFrame and classification rules. When you call classify(), it applies an inner helper function to tag each row with the appropriate category (or “Other” if none match), then tallies how many eclipses fall into each category. Finally, it prints a breakdown with counts and percentages, and returns both the annotated DataFrame and the category-count dictionar   Pan's Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04d5159-5b1f-4da9-896c-c9db6c66eccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EclipseClassifier:\n",
    "    def __init__(self, config, df):\n",
    "        self.df = df\n",
    "        self.classification_dict = config.classification_dict\n",
    "    def classify(self):\n",
    "        \"\"\"Classify eclipse types and output category counts.\"\"\"\n",
    "\n",
    "        def _classify_single(row):\n",
    "            \"\"\"Inner function: Classify a single row of eclipse data.\"\"\"\n",
    "            raw_type = row[\"Eclipse_Type\"]\n",
    "            for category, raw_list in self.classification_dict.items():\n",
    "                if raw_type in raw_list:\n",
    "                    return category\n",
    "            return \"Other (Other)\"\n",
    "\n",
    "        self.df[\"Eclipse_Category\"] = self.df.apply(_classify_single, axis=1)\n",
    "        # Count occurrences of each eclipse type\n",
    "        category_count = self.df[\"Eclipse_Category\"].value_counts().to_dict()\n",
    "\n",
    "        # Print statistical results\n",
    "        print(\"\\nEclipse Type Statistical Results:\")\n",
    "        total = len(self.df)\n",
    "        for cat, count in category_count.items():\n",
    "            print(f\"  {cat}: {count} times (accounting for {round(count / total * 100, 1)}%)\")\n",
    "        return self.df, category_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80a7b38-61d5-465c-bb74-9d39a47bfdb1",
   "metadata": {},
   "source": [
    "TipGenerator orchestrates the creation and storage of eclipse observation tips using the configured LLM client. In its constructor, it captures the OpenAI client, model name, and output directory. The public generate() method loops over each eclipse category, calls the private generate_observation_tip() (with retry logic to handle transient failures), collects the returned text, and prints progress. After generating tips for all categories, it assembles them into a DataFrame and writes an Excel file (eclipse_observation_tips.xlsx) into the output directory.  Jacky's Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fd401d-b4cc-4c4f-a76a-195ef14c6675",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TipGenerator:\n",
    "    def __init__(self, config):\n",
    "        self.client = config.client\n",
    "        self.model = config.model_name\n",
    "        # Store output directory for saving reports\n",
    "        self.output_dir = config.output_dir\n",
    "    def generate(self, category_count):\n",
    "        \"\"\"Generate observation tips for all eclipse categories and save to Excel.\"\"\"\n",
    "        observation_tips = {}\n",
    "        print(\"\\nCalling DeepSeek to generate observation tips:\")\n",
    "        for cat in category_count.keys():\n",
    "            print(f\"  Generating observation tips for [{cat}]...\")\n",
    "            try:\n",
    "                tip = self._generate_observation_tip(cat)\n",
    "                observation_tips[cat] = tip\n",
    "                print(f\"  Observation tips for [{cat}]:\\n{tip}\\n\")\n",
    "            except Exception as e:\n",
    "                observation_tips[cat] = f\"Generation failed: {str(e)[:50]}\"\n",
    "                print(f\"  Failed to generate observation tips for [{cat}]: {str(e)[:50]}\\n\")\n",
    "            time.sleep(1)  # Avoid rate limiting from high-frequency requests\n",
    "\n",
    "        # Save tips to Excel\n",
    "        tips_df = pd.DataFrame(\n",
    "            list(observation_tips.items()),\n",
    "            columns=[\"Eclipse Type\", \"Observation Tips\"]\n",
    "        )\n",
    "        tips_path = f\"{self.output_dir}/eclipse_observation_tips.xlsx\"\n",
    "        tips_df.to_excel(tips_path, index=False, engine=\"openpyxl\")\n",
    "        print(f\"Observation tips saved to: {tips_path}\")\n",
    "\n",
    "    @retry(\n",
    "        stop=stop_after_attempt(3),\n",
    "        wait=wait_exponential(multiplier=1, min=2, max=10),\n",
    "        retry=retry_if_exception_type((Exception,)),\n",
    "        reraise=False\n",
    "    )\n",
    "    def _generate_observation_tip(self, eclipse_category):\n",
    "        \"\"\"Private method: Call LLM to generate observation tips for a single eclipse type (with retry mechanism).\"\"\"\n",
    "        prompt = f\"\"\"As an astronomy popularization expert, provide observation tips for 【{eclipse_category}】, strictly following:\n",
    "1. 3 points: Safety Protection, Equipment Recommendations, Timing Selection;\n",
    "2. Each point no more than 40 characters, concise and practical language;\n",
    "3. Combine with observation scenarios of this eclipse type from 2001 to 2025.\n",
    "        \"\"\"\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Only retain observation tips, no extra expansion, colloquial language.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.6,\n",
    "            max_tokens=200\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b30c86c-b6d8-4530-80e8-c22d7c99efee",
   "metadata": {},
   "source": [
    "Visualizer manages all charting for eclipse trends and regional breakdowns. Its constructor accepts the filtered DataFrame, category counts, target locations, color mapping, output directory, and analysis period. The plot_frequency() method adds a year column, builds a stacked bar chart of eclipse counts over time and a separate bar chart of overall type distribution, then saves the combined figure. The plot_pie() method filters records by region keywords, writes per-region Excel files, generates styled pie charts for each location, and saves them with descriptive filenames.  Pan's Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab4682c-50a1-46b9-b62e-3449cc2d72e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Visualizer:\n",
    "    def __init__(self, config, df, category_count, target_locations, color_map, start_year, end_year):\n",
    "        self.df = df\n",
    "        self.category_count = category_count\n",
    "        self.target_locations = target_locations\n",
    "        self.color_map = color_map\n",
    "        self.output_dir = config.output_dir\n",
    "        # Analysis period\n",
    "        self.start_year = start_year\n",
    "        self.end_year = end_year\n",
    "        # Store analysis period\n",
    "        self.start_year = start_year\n",
    "        self.end_year = end_year\n",
    "    def plot_frequency(self):\n",
    "        \"\"\"Plot time-frequency and type distribution charts.\"\"\"\n",
    "        # Add year column for time-based grouping\n",
    "        self.df[\"Year\"] = self.df[\"Date\"].dt.year\n",
    "        # Count frequency by year and eclipse type\n",
    "        yearly_freq = self.df.groupby([\"Year\", \"Eclipse_Category\"]).size().unstack(fill_value=0)\n",
    "\n",
    "        # Configure font to support English (no need for Chinese font anymore)\n",
    "        plt.rcParams[\"axes.unicode_minus\"] = False  # Fix minus sign display issue\n",
    "\n",
    "        # Create subplots\n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 12))\n",
    "\n",
    "        # Subplot 1: Time-frequency stacked bar chart\n",
    "        colors = [self.color_map.get(col, \"#666\") for col in yearly_freq.columns]\n",
    "        yearly_freq.plot(\n",
    "            kind=\"bar\", stacked=True, ax=ax1, color=colors,\n",
    "            title=f\"Eclipse Frequency Trend ({self.start_year}-{self.end_year})\",\n",
    "            xlabel=\"Year\", ylabel=\"Number of Occurrences\"\n",
    "        )\n",
    "        ax1.legend(title=\"Eclipse Type\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "        ax1.grid(axis=\"y\", alpha=0.3)\n",
    "        ax1.title.set_fontsize(16)\n",
    "        ax1.title.set_fontweight(\"bold\")\n",
    "\n",
    "        # Subplot 2: Eclipse type distribution bar chart\n",
    "        cats = list(self.category_count.keys())\n",
    "        counts = [self.category_count[cat] for cat in cats]\n",
    "        bars = ax2.bar(cats, counts, color=[self.color_map.get(cat, \"#666\") for cat in cats])\n",
    "        # Add numerical labels to bars\n",
    "        for bar, count in zip(bars, counts):\n",
    "            ax2.text(\n",
    "                bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.2,\n",
    "                str(count), ha=\"center\", va=\"bottom\", fontsize=11, fontweight=\"bold\"\n",
    "            )\n",
    "        ax2.set_title(f\"Eclipse Type Distribution ({self.start_year}-{self.end_year})\", fontsize=16, fontweight=\"bold\")\n",
    "        ax2.set_xlabel(\"Eclipse Type\")\n",
    "        ax2.set_ylabel(\"Number of Occurrences\")\n",
    "        ax2.grid(axis=\"y\", alpha=0.3)\n",
    "\n",
    "        # Save plot\n",
    "        plt.tight_layout()\n",
    "        chart_path = f\"{self.output_dir}/eclipse_frequency_analysis.png\"\n",
    "        plt.savefig(chart_path, dpi=300, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "        print(f\"\\nTime-frequency chart saved to: {chart_path}\")\n",
    "\n",
    "    def plot_pie(self):\n",
    "        \"\"\"Plot regional eclipse type distribution pie charts.\"\"\"\n",
    "        # CN-EN region mapping (for keyword matching and filename)\n",
    "        cn_en_map = {\n",
    "            \"China\": [\"China\", \"Chinese\"],\n",
    "            \"USA\": [\"USA\", \"United States\", \"America\"],\n",
    "            \"Japan\": [\"Japan\", \"Japanese\"],\n",
    "            \"India\": [\"India\", \"Indian\"],\n",
    "            \"Australia\": [\"Australia\", \"Australian\"]\n",
    "        }\n",
    "\n",
    "        print(\"\\nBuilding regional solar eclipse records:\")\n",
    "        for location in self.target_locations:\n",
    "            # Get keywords for region matching\n",
    "            keywords = cn_en_map.get(location, [location])\n",
    "            # Fuzzy match visible regions\n",
    "            match_mask = pd.Series(False, index=self.df.index)\n",
    "            for kw in keywords:\n",
    "                match_mask |= self.df[\"Visible_Region\"].str.contains(kw, case=False, na=False)\n",
    "\n",
    "            # Filter and sort data for the current region\n",
    "            loc_df = self.df[match_mask].sort_values(\"Date\").reset_index(drop=True)\n",
    "            self.location_records[location] = loc_df\n",
    "\n",
    "            if len(loc_df) > 0:\n",
    "                # Save regional records to Excel\n",
    "                loc_en = cn_en_map.get(location, [location])[0]\n",
    "                loc_path = f\"{self.output_dir}/eclipses_in_{loc_en}.xlsx\"\n",
    "                loc_df.to_excel(loc_path, index=False, engine=\"openpyxl\")\n",
    "\n",
    "                # Plot pie chart for eclipse type distribution\n",
    "                loc_cat_count = loc_df[\"Eclipse_Category\"].value_counts()\n",
    "                pie_colors = [self.color_map.get(cat, \"#666\") for cat in loc_cat_count.index]\n",
    "\n",
    "                plt.figure(figsize=(10, 7))\n",
    "                wedges, texts, autotexts = plt.pie(\n",
    "                    loc_cat_count.values, labels=loc_cat_count.index,\n",
    "                    autopct=\"%1.1f%%\", colors=pie_colors, startangle=90\n",
    "                )\n",
    "                # Optimize text style\n",
    "                plt.setp(texts, fontsize=11)\n",
    "                plt.setp(autotexts, fontsize=10, fontweight=\"bold\", color=\"white\")\n",
    "                plt.title(\n",
    "                    f\"Eclipse Type Distribution in {location} ({self.start_year}-{self.end_year})\",\n",
    "                    fontsize=14, fontweight=\"bold\"\n",
    "                )\n",
    "\n",
    "                # Save pie chart\n",
    "                pie_path = f\"{self.output_dir}/{loc_en}_eclipse_distribution.png\"\n",
    "                plt.savefig(pie_path, dpi=300, bbox_inches=\"tight\")\n",
    "                plt.close()\n",
    "\n",
    "                # Print success message\n",
    "                print(f\"  {location}: {len(loc_df)} matching records found\")\n",
    "                print(f\"     - Matching keywords: {', '.join(keywords)}\")\n",
    "                print(f\"     - Record file: {loc_path}\")\n",
    "                print(f\"     - Pie chart file: {pie_path}\")\n",
    "            else:\n",
    "                print(f\"  {location}: No matching eclipse records found\")\n",
    "                print(f\"     - Attempted matching keywords: {', '.join(keywords)}\")\n",
    "                print(f\"     - Suggestion: Check if these keywords exist in the 'Visible_Region' column\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b73ed1-0926-4ccc-9c9f-5d2d89acfdef",
   "metadata": {},
   "source": [
    "CycleDetector examines the temporal spacing between successive eclipses to uncover repeating patterns and identify matches to the Saros cycle. In its constructor, it takes the cleaned DataFrame and retrieves the configured Saros period (in days). The detect() method sorts the DataFrame chronologically, computes the day-difference between each eclipse and its predecessor, and tallies any intervals that occur more than once. It then filters intervals within ±10 days of the Saros period to find theoretical Saros matches. Finally, it prints both the repeating-interval statistics and Saros-match results, and returns those two sets of findings.  Pan's Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9b4aa1-bb12-49af-b6f8-32b6b0525190",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleDetector:\n",
    "    def __init__(self, config, df):\n",
    "        self.df = df\n",
    "        self.saros_cycle = config.saros_cycle\n",
    "    def detect(self):\n",
    "        \"\"\"Detect potential repeating intervals and Saros cycle matches.\"\"\"\n",
    "        # The Saros cycle is an important astronomical cycle, approximately 6585.32 days (18 years, 11 days, 8 hours)\n",
    "        # Eclipses in the same Saros cycle have similar geometric characteristics and reappear in different regions of Earth.\n",
    "\n",
    "        # 1. Sort data by date and calculate intervals between consecutive eclipses\n",
    "        # Sorting ensures intervals are calculated for chronologically consecutive eclipses\n",
    "        sorted_df = self.df.sort_values(\"Date\").reset_index(drop=True)\n",
    "        # Calculate time difference (in days) from the previous eclipse\n",
    "        sorted_df[\"Interval_Days\"] = (sorted_df[\"Date\"] - sorted_df[\"Date\"].shift(1)).dt.days\n",
    "\n",
    "        # 2. Identify potential cycle patterns\n",
    "        # Filter intervals that occur at least twice (exclude 0 days to avoid duplicate records on the same day)\n",
    "        interval_counts = sorted_df[\"Interval_Days\"].value_counts()\n",
    "        potential_cycles = interval_counts[interval_counts >= 2].to_dict()\n",
    "\n",
    "        # 3. Verify Saros cycle matches\n",
    "        # Allow ±10 days tolerance (account for minor deviations in actual astronomical observations)\n",
    "        tolerance = 10  # Tolerance for Saros cycle matching (in days)\n",
    "        saros_matches = sorted_df[\n",
    "            (sorted_df[\"Interval_Days\"] >= self.saros_cycle - tolerance) &\n",
    "            (sorted_df[\"Interval_Days\"] <= self.saros_cycle + tolerance)\n",
    "            ][\"Interval_Days\"].tolist()\n",
    "\n",
    "        # 4. Print detection results\n",
    "        print(\"\\nEclipse Cycle Detection Results:\")\n",
    "        print(f\"  Potential repeating intervals (days) and occurrence count:\")\n",
    "        # Sort by occurrence count in descending order\n",
    "        for interval, count in sorted(potential_cycles.items(), key=lambda x: x[1], reverse=True):\n",
    "            print(f\"    {interval} days: {count} times\")\n",
    "        print(f\"  Saros cycle (theoretical value: {self.saros_cycle} days) matching results:\")\n",
    "        print(f\"    Qualified intervals: {saros_matches}\")\n",
    "        print(f\"    Matching count: {len(saros_matches)} times (tolerance: ±{tolerance} days)\")\n",
    "\n",
    "        return potential_cycles, saros_matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4fc7b6-08d4-40e7-867c-2145dca71dfe",
   "metadata": {},
   "source": [
    "EventMatcher scans the cleaned eclipse records for exact date matches against a predefined map of historical events. In its constructor, it stores the DataFrame and the event dictionary. The match() method formats each eclipse date as “YYYY-MM-DD,” then iterates through known event dates: if a match is found, it captures the eclipse’s type and visibility alongside the event description, prints success or failure messages, and returns a list of matched event records.  Pan's Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391725a5-1de8-411d-bff0-c682bae66a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EventMatcher:\n",
    "    def __init__(self, config, df):\n",
    "        self.df = df\n",
    "        self.historical_events = config.historical_events\n",
    "    def match(self):\n",
    "        \"\"\"Match eclipse dates to historical events.\"\"\"\n",
    "        # Convert date format to \"YYYY-MM-DD\" for easy matching\n",
    "        self.df[\"Date_Str\"] = self.df[\"Date\"].dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        print(\"\\nHistorical Event Matching Results:\")\n",
    "        event_matches = []\n",
    "        for event_date, event_desc in self.historical_events.items():\n",
    "            # Exact date matching\n",
    "            match_mask = self.df[\"Date_Str\"] == event_date\n",
    "            if match_mask.any():\n",
    "                # Get detailed information of the matching eclipse\n",
    "                eclipse_info = self.df[match_mask].iloc[0]\n",
    "                event_matches.append({\n",
    "                    \"Eclipse Date\": event_date,\n",
    "                    \"Eclipse Type\": eclipse_info[\"Eclipse_Category\"],\n",
    "                    \"Visible Region\": eclipse_info[\"Visible_Region\"],\n",
    "                    \"Associated Historical Event\": event_desc\n",
    "                })\n",
    "                print(f\"  Match successful: {event_date} - {event_desc}\")\n",
    "            else:\n",
    "                print(f\"  Match failed: {event_date} - {event_desc} (no eclipse record on this date)\")\n",
    "\n",
    "        return event_matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8498632-ded0-4140-ae3f-ca2c5d8d3333",
   "metadata": {},
   "source": [
    "CulturalAnalyzer leverages the LLM to produce narrative comparisons of eclipse interpretations across four ancient cultures. Its constructor receives the LLM client, model name, category counts, analysis period, and output path. The analyze() method loops through each culture, calls a private prompt function with the eclipse categories, handles retry and rate-limit delays, aggregates the returned texts, writes them to a structured TXT file, prints completion notices, and returns the assembled culture-to-analysis mapping. Jacky's Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bdedaf-0028-449c-b983-51bbe60775fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CulturalAnalyzer:\n",
    "    def __init__(self, config, category_count, start_year, end_year):\n",
    "        self.client = config.client\n",
    "        self.model = config.model_name\n",
    "        self.category_count = category_count\n",
    "        self.start_year = start_year\n",
    "        self.end_year = end_year\n",
    "        self.output_dir = config.output_dir\n",
    "        # Store analysis period and output directory\n",
    "        self.start_year = start_year\n",
    "        self.end_year = end_year\n",
    "        self.output_dir = config.output_dir\n",
    "    def analyze(self):\n",
    "        \"\"\"Generate cross-cultural eclipse interpretations and save to TXT.\"\"\"\n",
    "        # Select 4 representative cultures\n",
    "        cultures = [\"Ancient China\", \"Ancient Egypt\", \"Maya Civilization\", \"Medieval Europe\"]\n",
    "        eclipse_categories = list(self.category_count.keys())\n",
    "\n",
    "        print(\"\\nGenerating cross-cultural eclipse interpretation comparison:\")\n",
    "        cultural_analyses = {}\n",
    "        for culture in cultures:\n",
    "            print(f\"  Generating interpretation for [{culture}]...\")\n",
    "            try:\n",
    "                analysis = self._generate_cultural_analysis(culture, eclipse_categories)\n",
    "                cultural_analyses[culture] = analysis\n",
    "                print(f\"  Interpretation for [{culture}] completed\")\n",
    "            except Exception as e:\n",
    "                cultural_analyses[culture] = f\"Generation failed: {str(e)[:50]}\"\n",
    "                print(f\"  Failed to generate interpretation for [{culture}]: {str(e)[:50]}\")\n",
    "            time.sleep(1.5)  # Add delay to avoid rate limiting\n",
    "\n",
    "        # Save interpretation results to TXT\n",
    "        analysis_path = f\"{self.output_dir}/eclipse_cultural_comparison.txt\"\n",
    "        with open(analysis_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"Cross-Cultural Eclipse Interpretations ({self.start_year}-{self.end_year})\\n\")\n",
    "            f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "            for culture, content in cultural_analyses.items():\n",
    "                f.write(f\"[{culture}]\\n\")\n",
    "                f.write(content + \"\\n\\n\")\n",
    "                f.write(\"-\" * 30 + \"\\n\\n\")\n",
    "\n",
    "        print(f\"\\nCultural interpretation comparison saved to: {analysis_path}\")\n",
    "        return cultural_analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042f8ebf-be60-44a7-8f85-8a7fe385638b",
   "metadata": {},
   "source": [
    "DataSaver writes the fully processed DataFrame to an Excel file in the output directory and prints the save location. Orchestrator ties everything together: it loads and filters the data, runs classification, tip generation, visualization, cycle/event analyses, cultural interpretation, and then calls DataSaver to output the final dataset.  DOne by both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb806ed7-557e-462b-8cf3-abb83562a8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSaver:\n",
    "    def __init__(self, config, df):\n",
    "        self.df = df\n",
    "        self.output_dir = config.output_dir\n",
    "    def save_full(self):\n",
    "        \"\"\"Save the complete processed eclipse dataset.\"\"\"\n",
    "        full_path = f\"{self.output_dir}/full_processed_eclipse_data.xlsx\"\n",
    "        self.df.to_excel(full_path, index=False, engine=\"openpyxl\")\n",
    "        print(f\"\\nAll analyses completed! Fully processed data saved to: {full_path}\")\n",
    "        print(f\"All result files are located at: {os.path.abspath(self.output_dir)}\")\n",
    "\n",
    "# Orchestrator: orchestrates the full workflow by invoking all components\n",
    "class Orchestrator:\n",
    "    def __init__(self):\n",
    "        self.config = ConfigManager()\n",
    "    def run(self):\n",
    "        # 1. Load and preprocess data\n",
    "        df = DataLoader(self.config).load_and_preprocess()\n",
    "\n",
    "        # 2. Time range selection\n",
    "        print(\"\\nPlease select the time range for analysis:\")\n",
    "        print(\"1. 2001 - 2025 (All data)\")\n",
    "        print(\"2. Custom time range\")\n",
    "        choice = input(\"Please select an option (1 or 2): \").strip()\n",
    "        if choice == \"1\":\n",
    "            start_year, end_year = 2001, 2025\n",
    "        elif choice == \"2\":\n",
    "            try:\n",
    "                start_year = int(input(\"Please enter the start year (2001-2025): \").strip())\n",
    "                end_year = int(input(\"Please enter the end year (2001-2025): \").strip())\n",
    "                if not (2001 <= start_year <= 2025 and 2001 <= end_year <= 2025 and start_year <= end_year):\n",
    "                    print(\"Invalid range, using default (2001-2025)\")\n",
    "                    start_year, end_year = 2001, 2025\n",
    "            except ValueError:\n",
    "                print(\"Invalid input, using default (2001-2025)\")\n",
    "                start_year, end_year = 2001, 2025\n",
    "        else:\n",
    "            print(\"Invalid input, using default (2001-2025)\")\n",
    "            start_year, end_year = 2001, 2025\n",
    "\n",
    "        # Filter data by selected range\n",
    "        df = df[(df[\"Date\"].dt.year >= start_year) & (df[\"Date\"].dt.year <= end_year)].copy()\n",
    "        print(f\"\\nAnalysis period: {start_year}-{end_year}, records: {len(df)}\")\n",
    "\n",
    "        # 3. Classify eclipses\n",
    "        df, category_count = EclipseClassifier(self.config, df).classify()\n",
    "\n",
    "        # 4. Generate observation tips\n",
    "        TipGenerator(self.config).generate(category_count)\n",
    "\n",
    "        # 5. Visualization\n",
    "        vis = Visualizer(\n",
    "            self.config,\n",
    "            df,\n",
    "            category_count,\n",
    "            self.config.target_locations,\n",
    "            self.config.color_map,\n",
    "            start_year,\n",
    "            end_year\n",
    "        )\n",
    "        vis.plot_frequency()\n",
    "        vis.plot_pie()\n",
    "\n",
    "        # 6. Cycle detection and historical event matching\n",
    "        CycleDetector(self.config, df).detect()\n",
    "        EventMatcher(self.config, df).match()\n",
    "\n",
    "        # 7. Cross-cultural interpretation\n",
    "        CulturalAnalyzer(self.config, category_count, start_year, end_year).analyze()\n",
    "\n",
    "        # 8. Save final data\n",
    "        DataSaver(self.config, df).save_full()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc9638f-cd5a-41af-9d76-8a0f7fcd2f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Create analyzer instance\n",
    "    analyzer = Orchestrator()\n",
    "    # Run full workflow analysis\n",
    "    analyzer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637750c4",
   "metadata": {},
   "source": [
    "End of the program"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
